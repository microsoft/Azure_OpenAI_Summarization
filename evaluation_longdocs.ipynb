{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "# from langchain.chat_models import AzureChatOpenAI\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser,StructuredOutputParser,ResponseSchema\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summary.doc_summary import DocSummary\n",
    "from summary.doc_summary import summaryMetrics\n",
    "from summary.doc_summary import NLGMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scientific papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hugging face dataset \n",
    "import pandas as pd\n",
    "\n",
    "df_papers = pd.read_csv(\"./data/scientific-papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_papers.shape, df_papers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df_papers[(df_papers[\"num_tokens\"] >= 20000) & (df_papers[\"num_tokens\"] <30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.shape,df_selected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_summary_kmeans(text):\n",
    "    docSum = DocSummary(text=text)\n",
    "    return docSum.summary_long()\n",
    "\n",
    "def get_summary_agglo(text):\n",
    "    docSum = DocSummary(text=text)\n",
    "    return docSum.summary_long(clustering_type=\"agglomerative\")\n",
    "\n",
    "def get_summary_mapreduce(text):\n",
    "    docSum = DocSummary(text=text)\n",
    "    return docSum.summary_medium()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(summary_kmeans,summary_agglomerative,summary_mapreduce):\n",
    "    summary_dict = {}\n",
    "    summary_dict[\"sum_kmeans\"] = summary_kmeans[0]\n",
    "    summary_dict[\"resp_time_kmeans\"] = summary_kmeans[1]\n",
    "    summary_dict[\"sum_agglomerative\"] = summary_agglomerative[0]\n",
    "    summary_dict[\"resp_time_agglomerative\"] = summary_agglomerative[1]\n",
    "    summary_dict[\"sum_mapreduce\"] = summary_mapreduce[0]\n",
    "    summary_dict[\"resp_time_mapreduce\"] = summary_mapreduce[1]\n",
    "    # summary_dict[\"article\"] = df_selected.iloc[n][\"article\"]\n",
    "    # summary_dict[\"abstract\"] = df_selected.iloc[n][\"abstract\"]\n",
    "    # summary_dict[\"section_names\"] = df_selected.iloc[n][\"section_names\"]\n",
    "    # summary_dict[\"num_tokens\"] = df_selected.iloc[n][\"num_tokens\"]\n",
    "    return summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose 10 data points randomly\n",
    "import random\n",
    "\n",
    "# Choose 10 numbers randomly from the range 1 to 100\n",
    "random_numbers = random.sample(range(1, df_selected.shape[0]), 10)\n",
    "\n",
    "print(random_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in random_numbers[6:]:\n",
    "    print(n)\n",
    "    summary_kmeans,summary_agglomerative,summary_mapreduce= \"\",\"\",\"\"\n",
    "    text = df_selected.iloc[n][\"article\"]\n",
    "    num_tokens = df_selected.iloc[n][\"num_tokens\"]\n",
    "    print(num_tokens)\n",
    "    summary_kmeans = get_summary_kmeans(text)\n",
    "    summary_agglomerative = get_summary_agglo(text)\n",
    "    summary_mapreduce = get_summary_mapreduce(text)\n",
    "    summary_dict = process_results(summary_kmeans,summary_agglomerative,summary_mapreduce)\n",
    "    summary_dict[\"article\"] = df_selected.iloc[n][\"article\"]\n",
    "    summary_dict[\"abstract\"] = df_selected.iloc[n][\"abstract\"]\n",
    "    summary_dict[\"section_names\"] = df_selected.iloc[n][\"section_names\"]\n",
    "    summary_dict[\"num_tokens\"] = df_selected.iloc[n][\"num_tokens\"]\n",
    "    summary_list.append(summary_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/paper_summary_gpt35_201k.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/paper_summary_gpt35_201k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df.drop(columns=[\"article\",\"section_names\"])\n",
    "df_data.shape,df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calucalte metrics\n",
    "def get_metrics(candidate,reference):\n",
    "    metrics = summaryMetrics(summary_text=candidate,reference_text=reference)\n",
    "    rouge_1_p,rouge_1_r,rouge_1_f,rouge_2_p,rouge_2_r,rouge_2_f,rouge_l_p,rouge_l_r,rouge_l_f = metrics.get_rouge_score()\n",
    "    bert_p,bert_r,bert_f = metrics.get_bert_score()\n",
    "    return  rouge_1_p,rouge_1_r,rouge_1_f,rouge_2_p,rouge_2_r,rouge_2_f,rouge_l_p,rouge_l_r,rouge_l_f,bert_p,bert_r,bert_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['kmeans_rouge_1_p', 'kmeans_rouge_1_r','k_means_rouge_1_f','kmeans_rouge_2_p', 'kmeans_rouge_2_r','kmeans_rouge_3_f','kmeans_rouge_l_p', 'kmeans_rouge_l_r','kmeans_rouge_l_f','kmeans_bert_p','kmeans_bert_r','kmeans_bert_f']] = df_data.apply(lambda row: pd.Series(get_metrics(row['sum_kmeans'],row['abstract'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['agglomerative_rouge_1_p', 'agglomerative_rouge_1_r','agglomerative_rouge_1_f','agglomerative_rouge_2_p', 'agglomerative_rouge_2_r','agglomerative_rouge_3_f','agglomerative_rouge_l_p', 'agglomerative_rouge_l_r','agglomerative_rouge_l_f','agglomerative_bert_p','agglomerative_bert_r','agglomerative_bert_f']] = df_data.apply(lambda row: pd.Series(get_metrics(row['sum_agglomerative'],row['abstract'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['mapreduce_rouge_1_p', 'mapreduce_rouge_1_r','mapreduce_rouge_1_f','mapreduce_rouge_2_p', 'mapreduce_rouge_2_r','mapreduce_rouge_3_f','mapreduce_rouge_l_p', 'mapreduce_rouge_l_r','mapreduce_rouge_l_f','mapreduce_bert_p','mapreduce_bert_r','mapreduce_bert_f']] = df_data.apply(lambda row: pd.Series(get_metrics(row['sum_mapreduce'],row['abstract'])) if row['sum_mapreduce'] != '' else pd.Series(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dropna(inplace=True)\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create subplots (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Plot bar graph for Bert P Scores\n",
    "selected_cols_p = [\"kmeans_bert_p\", \"agglomerative_bert_p\", \"mapreduce_bert_p\"]\n",
    "df_data[selected_cols_p].mean().plot(kind='bar', ax=axes[0], edgecolor='black')\n",
    "axes[0].set_title('Bert P Scores')\n",
    "axes[0].set_ylabel('Scores')\n",
    "axes[0].set_ylim(0.82, 0.86)\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot bar graph for Bert R Scores\n",
    "selected_cols_r = [\"kmeans_bert_r\", \"agglomerative_bert_r\", \"mapreduce_bert_r\"]\n",
    "df_data[selected_cols_r].mean().plot(kind='bar', ax=axes[1], edgecolor='black')\n",
    "axes[1].set_title('Bert R Scores')\n",
    "axes[1].set_ylabel('Scores')\n",
    "axes[1].set_ylim(0.75, 0.82)\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create subplots (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(5,5))\n",
    "\n",
    "# # Plot bar graph for resp time\n",
    "selected_cols = [\"resp_time_kmeans\",\"resp_time_agglomerative\",\"resp_time_mapreduce\"]\n",
    "# Plot each column against column 'n'\n",
    "\n",
    "plt.scatter(df_data['num_tokens'], df_data[\"resp_time_kmeans\"],label=\"response_time_kmeans\")\n",
    "plt.scatter(df_data['num_tokens'], df_data[\"resp_time_agglomerative\"], label=\"response_time_agglomerative\")\n",
    "plt.scatter(df_data['num_tokens'], df_data[\"resp_time_mapreduce\"],label=\"response_time_mapreduce\")\n",
    "\n",
    "\n",
    "plt.xlabel('num tokens')\n",
    "plt.ylabel('response time')\n",
    "plt.title('Response time')\n",
    "plt.legend()\n",
    "axes.set_ylim(0, 180)\n",
    "plt.grid(True)\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "# plt.ylim(0.8, 0.9)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLG Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlg_metrics(doc,summary):\n",
    "    metrics = NLGMetrics(doc,summary)\n",
    "    metric_scores = metrics.get_nlg_metrics()\n",
    "    return metric_scores['coherence'],metric_scores['consistency'],metric_scores['fluency'],metric_scores['relevance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The length of the document exceeds the permissible token limit for long documents. Hence abstract is used instead of original article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['k_means_coherence','kmeans_consistency','kmeans_fluency','k_meansrelevance']] = df_data.apply(lambda row: pd.Series(nlg_metrics(row['abstract'],row['sum_kmeans'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['agglomerative_coherence','agglomerative_consistency','agglomerative_fluency','agglomerative_relevance']] = df_data.apply(lambda row: pd.Series(nlg_metrics(row['abstract'],row['sum_agglomerative'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['mapreduce_coherence','mapreduce_consistency','mapreduce_fluency','mapreduce_relevance']] = df_data.apply(lambda row: pd.Series(nlg_metrics(row['abstract'],row['sum_mapreduce'])), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Print all the available datasets\n",
    "from huggingface_hub import list_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_ds = load_dataset('scientific_papers','arxiv',split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_list = []\n",
    "\n",
    "for d in papers_ds :\n",
    "    text = d[\"article\"]\n",
    "    abstract = d[\"abstract\"]\n",
    "    section_names = d[\"section_names\"]\n",
    "    d[\"num_tokens\"] = llm.get_num_tokens(text)\n",
    "    papers_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(papers_list)\n",
    "df_raw.shape,df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_csv(\"./data/scientific-papers.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summaryappenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from summary.doc_summary import DocSummary\n",
    "from summary.doc_summary import summaryMetrics\n",
    "from summary.doc_summary import NLGMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read bill_sum_data.csv \n",
    "df_data = pd.read_csv(\"./data/bill_sum_data.csv\")\n",
    "df_data.shape,df_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_small_medium = 1500\n",
    "# threshold_medium_long = 3000\n",
    "# threshold_length_limit = 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter documents with len < 10000\n",
    "df_long = df_data[df_data[\"text_len\"] >= 10000].copy()\n",
    "df_long.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.drop(columns = [\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.reset_index(drop=True)\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    docSum = DocSummary(text=text)\n",
    "    return docSum.llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[\"num_tokens\"] = df_long[\"text\"].apply(lambda x : get_tokens(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_long(text):\n",
    "    docSum = DocSummary(text=text)\n",
    "    summary_kmeans = docSum.summary_long()\n",
    "    summary_agglomerative = docSum.summary_long(clustering_type=\"agglomerative\")\n",
    "    summary_map_reduce = docSum.summary_medium()\n",
    "    return summary_kmeans[0],summary_kmeans[1],summary_agglomerative[0],summary_agglomerative[1],summary_map_reduce[0],summary_map_reduce[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_long.loc[df_long.index[0], 'text']\n",
    "results = get_summary_long(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num tokens > 2000. We will use long doc summarization \n",
    "# reduce the chun sizes in doc summary class\n",
    "# expt with num of clusters\n",
    "df_long[['summary_kmeans', 'kmeans_resp_time','summary_agglomerative', 'agglomerative_resp_time','summary_mapreduce','mapreduce_resp_time']] = df_long.apply(lambda row: pd.Series(get_summary_long(row['text'])), axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.to_csv(\"./data/long_doc_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(candidate,reference):\n",
    "    metrics = summaryMetrics(summary_text=candidate,reference_text=reference)\n",
    "    rouge_1_p,rouge_1_r,rouge_1_f,rouge_2_p,rouge_2_r,rouge_2_f,rouge_l_p,rouge_l_r,rouge_l_f = metrics.get_rouge_score()\n",
    "    bert_p,bert_r,bert_f = metrics.get_bert_score()\n",
    "    return  rouge_1_p,rouge_1_r,rouge_1_f,rouge_2_p,rouge_2_r,rouge_2_f,rouge_l_p,rouge_l_r,rouge_l_f,bert_p,bert_r,bert_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[['kmeans_rouge_1_p', 'kmeans_rouge_1_r','k_means_rouge_1_f','kmeans_rouge_2_p', 'kmeans_rouge_2_r','kmeans_rouge_3_f','kmeans_rouge_l_p', 'kmeans_rouge_l_r','kmeans_rouge_l_f','kmeans_bert_p','kmeans_bert_r','kmeans_bert_f']] = df_long.apply(lambda row: pd.Series(get_metrics(row['summary_kmeans'],row['summary'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[['agglomerative_rouge_1_p', 'agglomerative_rouge_1_r','agglomerative_rouge_1_f','agglomerative_rouge_2_p', 'agglomerative_rouge_2_r','agglomerative_rouge_3_f','agglomerative_rouge_l_p', 'agglomerative_rouge_l_r','agglomerative_rouge_l_f','agglomerative_bert_p','agglomerative_bert_r','agglomerative_bert_f']] = df_long.apply(lambda row: pd.Series(get_metrics(row['summary_agglomerative'],row['summary'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[['mapreduce_rouge_1_p', 'mapreduce_rouge_1_r','mapreduce_rouge_1_f','mpreduce_rouge_2_p', 'mapreduce_rouge_2_r','mapreduce_rouge_3_f','mapreduce_rouge_l_p', 'mapreduce_rouge_l_r','mapreduce_rouge_l_f','mapreduce_bert_p','mapreduce_bert_r','mapreduce_bert_f']] = df_long.apply(lambda row: pd.Series(get_metrics(row['summary_mapreduce'],row['summary'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.to_csv(\"./data/long_doc_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create subplots (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
    "\n",
    "# Plot bar graph for columns r_1, r_2, r_3\n",
    "selected_cols = [\"kmeans_bert_p\",\"agglomerative_bert_p\",\"mapreduce_bert_p\"]\n",
    "df_long[selected_cols].mean().plot(kind='bar', ax=axes[0][0], edgecolor='black')\n",
    "\n",
    "axes[0][0].set_title('Bert P Scores')\n",
    "axes[0][0].set_ylabel('Scores')\n",
    "\n",
    "# Plot bar graph bert r\n",
    "selected_cols = [\"kmeans_bert_r\",\"agglomerative_bert_r\",\"mapreduce_bert_r\"]\n",
    "df_long[selected_cols].mean().plot(kind='bar', ax=axes[0][1], edgecolor='black')\n",
    "axes[0][1].set_title('Bert R scores')\n",
    "axes[0][1].set_ylabel('Scores')\n",
    "\n",
    "\n",
    "# Plot bar graph for columns other_col_1, other_col_2\n",
    "selected_cols = [\"kmeans_bert_f\",\"agglomerative_bert_f\",\"mapreduce_bert_f\"]\n",
    "df_long[selected_cols].mean().plot(kind='bar', ax=axes[1][0], edgecolor='black')\n",
    "axes[1][0].set_title('Bert F scores')\n",
    "axes[1][0].set_ylabel('Scores')\n",
    "\n",
    "# Plot bar graph for resp time\n",
    "selected_cols = [\"kmeans_resp_time\",\"agglomerative_resp_time\",\"mapreduce_resp_time\"]\n",
    "df_long[selected_cols].mean().plot(kind='bar', ax=axes[1][1], edgecolor='black')\n",
    "axes[1][1].set_title('Response Time')\n",
    "axes[1][1].set_ylabel('Response time(sec)')\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert score plots\n",
    "\n",
    "# Create subplots (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8, 6))\n",
    "\n",
    "# Plot bar graph for columns r_1, r_2, r_3\n",
    "selected_cols = [\"k_means_rouge_1_f\",\"agglomerative_rouge_1_f\",\"mapreduce_rouge_1_f\"]\n",
    "df_long[selected_cols].mean().plot(kind='bar', ax=axes[0], edgecolor='black')\n",
    "\n",
    "axes[0].set_title('Rouge 1 F Scores')\n",
    "axes[0].set_ylabel('Scores')\n",
    "\n",
    "# Plot bar graph for columns other_col_1, other_col_2\n",
    "selected_cols = [\"kmeans_rouge_3_f\",\"agglomerative_rouge_3_f\",\"mapreduce_rouge_3_f\"]\n",
    "df_long[selected_cols].mean().plot(kind='bar', ax=axes[1], edgecolor='black')\n",
    "axes[1].set_title('Rouge 2 F scores')\n",
    "axes[1].set_ylabel('Scores')\n",
    "\n",
    "\n",
    "# Plot bar graph for columns other_col_1, other_col_2\n",
    "selected_cols = [\"kmeans_rouge_l_f\",\"agglomerative_rouge_l_f\",\"mapreduce_rouge_l_f\"]\n",
    "df_long[selected_cols].mean().plot(kind='bar', ax=axes[2], edgecolor='black')\n",
    "axes[2].set_title('Rouge l F scores')\n",
    "axes[2].set_ylabel('Scores')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(text):\n",
    "    docSum = DocSummary(config_file=\"./config/config.json\",text=text)\n",
    "    num_tokens = docSum.llm.get_num_tokens(text)\n",
    "    if num_tokens < threshold_small_medium:\n",
    "        return docSum.summary_short()\n",
    "    elif num_tokens < threshold_medium_long:\n",
    "        return docSum.summary_medium()\n",
    "    elif num_tokens < threshold_length_limit:\n",
    "        return docSum.summary_long()\n",
    "    else:\n",
    "        return \"too long to process\",\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['aoai_summary', 'response_time']] = df_data.apply(lambda row: pd.Series(get_summary(row['text'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_csv(\"./data/long_doc_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Evaluation - Rouge & Bert scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load output_data csv\n",
    "df_data = pd.read_csv(\"./data/output_data.csv\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['rouge_1_p', 'rouge_1_r','rouge_1_f','rouge_2_p', 'rouge_2_r','rouge_3_f','rouge_l_p', 'rouge_l_r','rouge_l_f','bert_p','bert_r','bert_f']] = df_data.apply(lambda row: pd.Series(get_metrics(row['aoai_summary'],row['summary'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summaryappenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
